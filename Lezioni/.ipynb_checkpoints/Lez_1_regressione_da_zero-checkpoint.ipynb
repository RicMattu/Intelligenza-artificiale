{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51c1429b-7245-483b-9703-59258b7853bb",
   "metadata": {},
   "source": [
    "L'obiettivo di questa lezione è costruire una rete neurale (MLP) che faccia una regressione.  \n",
    "La costruiremo in modi diversi procedendo per difficoltà crescenti:\n",
    "1. la costruiamo da zero usando solo operazioni algebriche\n",
    "2. usiamo Sequential\n",
    "3. usiamo la libreria torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797b0a4b-6a3a-492d-a5a0-67a4de6f02f3",
   "metadata": {},
   "source": [
    "### Livello 1.1 \n",
    "Dataset con dimensioni ridotte  \n",
    "Regressione 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5df441-b808-4d05-8908-11f8f4131f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4742e1e-f932-4461-bf86-2d36194325be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "x = np.linspace(\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df6961b-3557-4dc6-a8f8-86a683db7989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca2bc7-148a-40a2-b3fd-873d7645c1af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab29e48-5850-40e6-b5eb-d5d4e2e452df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8812c0cd-1bfa-4377-b8f6-4cad930689a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Nov 28 15:18:16 2025\n",
    "\n",
    "@author: User\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "x = np.linspace(0, 10, num=50)\n",
    "\n",
    "y_t = np.pi * x + np.e\n",
    "\n",
    "# splitting\n",
    "\n",
    "x_train = x[0:40]\n",
    "x_test = x[40:]\n",
    "\n",
    "y_t_train = y_t[0:40]\n",
    "y_t_test = y_t[40:]\n",
    "\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.e**(-x))\n",
    "    \n",
    "w = 10*np.random.rand(2)\n",
    "\n",
    "def MLP(x):\n",
    "    y = w[1]*x + w[0]\n",
    "    return y\n",
    "    \n",
    "def loss(y_t,y_pred):\n",
    "    err = np.mean((y_t-y_pred)**2)\n",
    "    return err\n",
    "\n",
    "L = []\n",
    "\n",
    "# Forward\n",
    "y_pred = MLP(x)\n",
    "L.append(loss(y_t,y_pred))\n",
    "print(f\"Initial Loss:{L[0]}\")\n",
    "\n",
    "\n",
    "# Backpropagation\n",
    "epochs = 5\n",
    "lr = 0.0001\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # forward\n",
    "    y_pred = MLP(x)\n",
    "    \n",
    "    # compute loss\n",
    "    L.append(loss(y_t,y_pred))\n",
    "    print(f\"Loss at epoch {epoch} = {L[epoch]}\")\n",
    "    \n",
    "    # gradients\n",
    "    grad = [np.mean(y_t-y_pred), np.mean(y_t-y_pred)*x_train]\n",
    "    \n",
    "    # update wights\n",
    "    w = w - lr*grad\n",
    "    \n",
    "    \n",
    "print(f\"Final loss: {L[epochs]}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
